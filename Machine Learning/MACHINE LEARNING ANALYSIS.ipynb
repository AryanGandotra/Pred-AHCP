{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MACHINE LEARNING ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the pandas numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# finding present working directory\n",
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "# changing the working directory\n",
    "os.chdir('/home/researchlab/Downloads/CODES/Data')\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "#checking the files in the directory\n",
    "os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading dataset file\n",
    "df_union = pd.read_csv(\"9_dataset_subset_unique.csv\")\n",
    "print(df_union.shape)\n",
    "\n",
    "#isolating the column names of the dataset\n",
    "df_union_columns = df_union.columns\n",
    "print(df_union_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating X and Y for machine learning analysis by removing the ID, label and Sequence\n",
    "X_union = df_union.drop(['ID','Label','Sequence'],axis=1)\n",
    "Y_union = df_union['Label']\n",
    "Y_union = np.ravel(Y_union)\n",
    "print(X_union.shape, Y_union.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting X max values for each column\n",
    "X_union.max().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolating the X columns with maximum value greater than 1.0\n",
    "df1 = X_union.loc[:, (X_union.max() > 1.0)]\n",
    "\n",
    "#develop a for loop to divide each value in column by 100\n",
    "for i in df1.columns:\n",
    "    X_union[i] = df1[i].div(100)\n",
    "\n",
    "df1.describe()\n",
    "X_union.describe()\n",
    "\n",
    "#plotting X max values for each column\n",
    "X_union.max().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing the train test split for unique and intersection dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_union_train, X_union_test, Y_union_train, Y_union_test = train_test_split(X_union, Y_union, test_size=0.2, random_state=99)\n",
    "print(X_union_train.shape, X_union_test.shape, Y_union_train.shape, Y_union_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the validation file \n",
    "df_validation = pd.read_csv(\"Validation.csv\")\n",
    "print(df_validation.shape)\n",
    "\n",
    "#creating a subset of validation dataset using columns stored in df_columns\n",
    "df_validation = df_validation[df_union_columns]\n",
    "print(df_validation.shape)\n",
    "\n",
    "#creating X_val and Y_val for validation dataset by removing the ID, label and Sequence\n",
    "X_val = df_validation.drop(['ID','Label','Sequence'],axis=1)\n",
    "Y_val = df_validation['Label']\n",
    "Y_val = np.ravel(Y_val)\n",
    "\n",
    "#checking the shape of X_val and Y_val\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)\n",
    "\n",
    "# splitting the validation dataset into train and test\n",
    "X_val_train, X_val_test, Y_val_train, Y_val_test = train_test_split(X_val, Y_val, test_size=0.2, random_state=99)\n",
    "print(X_val_train.shape, X_val_test.shape, Y_val_train.shape, Y_val_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Defining the classifiers\n",
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(Max depth=15, Min_sample_leaf=02, N_estimators=100, Max_features=15),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=100),\n",
    "    \n",
    "    'Support Vector Machine poly': SVC(kernel='poly', C=1.0, gamma='scale', random_state=42, probability=True),\n",
    "    'Support Vector Machine rbf': SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42, probability=True),\n",
    "    'Support Vector Machine Linear': SVC(kernel='linear', C=1.0, random_state=42, probability=True),\n",
    "    'Support Vector Machine Sigmoid': SVC(kernel='sigmoid', C=1.0, gamma='scale',random_state=42, probability=True),\n",
    "    # using XGBoost classifier\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42),\n",
    "    'Gaussian Naive Bayes': GaussianNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "results_list = []\n",
    "\n",
    "# Loop through each classifier\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\nTraining and evaluating {clf_name}...\\n\")\n",
    "    \n",
    "    # Training the model on the training set\n",
    "    clf.fit(X_union_train, Y_union_train)\n",
    "    \n",
    "    # Testing set predictions\n",
    "    Y_union_pred = clf.predict(X_union_test)\n",
    "    \n",
    "    # Model evaluation on the first validation set\n",
    "    accuracy_test = metrics.accuracy_score(Y_union_test, Y_union_pred)\n",
    "    precision_test = metrics.precision_score(Y_union_test, Y_union_pred)\n",
    "    recall_test = metrics.recall_score(Y_union_test, Y_union_pred)\n",
    "    specificity_test = metrics.recall_score(Y_union_test, Y_union_pred, pos_label=0)\n",
    "    auroc_test = metrics.roc_auc_score(Y_union_test, clf.predict_proba(X_union_test)[:, 1])\n",
    "    mcc_test = metrics.matthews_corrcoef(Y_union_test, Y_union_pred)\n",
    "    f1_test = metrics.f1_score(Y_union_test, Y_union_pred)\n",
    "\n",
    "    # Evaluation on the validation set\n",
    "    Y_val_pred = clf.predict(X_val)\n",
    "    accuracy_val = metrics.accuracy_score(Y_val, Y_val_pred)\n",
    "\n",
    "    # 10-fold cross-validation\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    Stratified_accuracy_scores = cross_val_score(clf, X_union, Y_union, cv=cv, scoring='accuracy')\n",
    "    Stratified_accuracy_scores = Stratified_accuracy_scores.round(2)\n",
    "\n",
    "    # Save results to the DataFrame\n",
    "    #results_df = results_df.append({\n",
    "    results_list.append({\n",
    "        'Classifier': clf_name,\n",
    "        'Testing Accuracy': accuracy_test,\n",
    "        'Testing Precision': precision_test,\n",
    "        'Testing Recall': recall_test,\n",
    "        'Testing Specificity': specificity_test,\n",
    "        'Testing AUROC': auroc_test,\n",
    "        'Testing MCC': mcc_test,\n",
    "        'Testing F1 Score': f1_test,\n",
    "        'Validation Accuracy': accuracy_val,\n",
    "        'Stratified 10-fold CV Accuracy Scores': Stratified_accuracy_scores,\n",
    "        'Mean Stratified CV Accuracy': np.mean(Stratified_accuracy_scores ),\n",
    "        'Std Stratified CV Accuracy': np.std(Stratified_accuracy_scores )\n",
    "    })\n",
    "    \n",
    "# Convert the list to a DataFrame\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(\"\\nResults DataFrame:\")\n",
    "print(results_df)\n",
    "print(results_df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving all the numbers to the second's decimal place\n",
    "results_df = results_df.round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving results_df to csv file\n",
    "results_df.to_csv('results_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# developing a pkl file for random forest classifier used in the classifier method\n",
    "import pickle\n",
    "pickle.dump(classifiers['Random Forest'], open('random_forest.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
